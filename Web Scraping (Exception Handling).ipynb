{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a51f8984",
   "metadata": {},
   "source": [
    "## Web Scraping  with Beautiful Soup, Selenium and Exception Handling concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a645dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89962d6",
   "metadata": {},
   "source": [
    "Importing all the necessary dependencies here.\n",
    "\n",
    "Scrape the details of most viewed videos on YouTube from Wikipedia: Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50511cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from our URL is: <Response [200]>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views_in_Billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video_Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.                Phonics Song with Two Words   \n",
       "7    8.                                Uptown Funk   \n",
       "8    9.  Learning Colors – Colorful Eggs on a Farm   \n",
       "9   10.   Masha and the Bear – Recipe for Disaster   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                          Wheels on the Bus   \n",
       "12  13.                             Dame Tu Cosita   \n",
       "13  14.                                      Sugar   \n",
       "14  15.                                       Roar   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                                      Sorry   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                                     Axel F   \n",
       "19  20.                             Girls Like You   \n",
       "20  21.                                      Faded   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                        Baa Baa Black Sheep   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                                   Bailando   \n",
       "25  26.                                    Lean On   \n",
       "26  27.                               Shake It Off   \n",
       "27  28.                                    Perfect   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                                   Mi Gente   \n",
       "\n",
       "                                    Artist_Name        Upload_Date  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                    Luis Fonsi   January 12, 2017   \n",
       "2                                   LooLoo Kids    October 8, 2016   \n",
       "3                                    Ed Sheeran   January 30, 2017   \n",
       "4                                   Wiz Khalifa      April 6, 2015   \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "6                                     ChuChu TV      March 6, 2014   \n",
       "7                                   Mark Ronson  November 19, 2014   \n",
       "8                                   Miroshka TV  February 27, 2018   \n",
       "9                                    Get Movies   January 31, 2012   \n",
       "10                                          Psy      July 15, 2012   \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "12                                    El Chombo      April 5, 2018   \n",
       "13                                     Maroon 5   January 14, 2015   \n",
       "14                                   Katy Perry  September 5, 2013   \n",
       "15                                  OneRepublic       May 31, 2013   \n",
       "16                                Justin Bieber   October 22, 2015   \n",
       "17                                   Ed Sheeran    October 7, 2014   \n",
       "18                                   Crazy Frog      June 16, 2009   \n",
       "19                                     Maroon 5       May 31, 2018   \n",
       "20                                  Alan Walker   December 3, 2015   \n",
       "21                                   Katy Perry  February 20, 2014   \n",
       "22                   Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "23                                    Passenger      July 25, 2012   \n",
       "24                             Enrique Iglesias     April 11, 2014   \n",
       "25                                  Major Lazer     March 22, 2015   \n",
       "26                                 Taylor Swift    August 18, 2014   \n",
       "27                                   Ed Sheeran   November 9, 2017   \n",
       "28                                      Shakira       June 4, 2010   \n",
       "29                                     J Balvin      June 29, 2017   \n",
       "\n",
       "   Views_in_Billions  \n",
       "0              10.70  \n",
       "1               7.85  \n",
       "2               6.35  \n",
       "3               5.72  \n",
       "4               5.51  \n",
       "5               5.38  \n",
       "6               4.63  \n",
       "7               4.57  \n",
       "8               4.57  \n",
       "9               4.50  \n",
       "10              4.43  \n",
       "11              4.07  \n",
       "12              3.94  \n",
       "13              3.70  \n",
       "14              3.58  \n",
       "15              3.58  \n",
       "16              3.55  \n",
       "17              3.45  \n",
       "18              3.36  \n",
       "19              3.29  \n",
       "20              3.28  \n",
       "21              3.27  \n",
       "22              3.24  \n",
       "23              3.23  \n",
       "24              3.21  \n",
       "25              3.21  \n",
       "26              3.17  \n",
       "27              3.17  \n",
       "28              3.14  \n",
       "29              3.08  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "driver.find_element_by_xpath(\"//b\").click()\n",
    "records = []\n",
    "for row in driver.find_elements_by_xpath(\"(//table[@class='wikitable sortable jquery-tablesorter'])[1]//tr\")[1:-1]:\n",
    "    temp = ''\n",
    "    for element in row.find_elements_by_xpath(\".//td\"):        \n",
    "        temp += element.text + '|'\n",
    "    records.append(temp.split('|')[:-2])\n",
    "\n",
    "df = pd.DataFrame(records, columns=['Rank', 'Video_Name', 'Artist_Name', 'Views_in_Billions', 'Upload_Date'])\n",
    "\n",
    "arranged_cols = ['Rank', 'Video_Name', 'Artist_Name', 'Upload_Date', 'Views_in_Billions']\n",
    "\n",
    "df.Video_Name = df.Video_Name.apply(lambda x:x[:-4].strip('\"'))\n",
    "df = df[arranged_cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35202ce2",
   "metadata": {},
   "source": [
    "#### 2) Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9d69af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Match, Series, Place, Date, Time]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the bcci.tv\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#going to international fixtures page\n",
    "\n",
    "try:\n",
    "    fixtures=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")    \n",
    "    fixtures.click()\n",
    "    driver.get(fixtures.get_attribute('href'))\n",
    "except:\n",
    "    print(\"exception\")\n",
    "    \n",
    "    \n",
    "\n",
    "time.sleep(2)\n",
    "# scrape match details urls from xpath    \n",
    "urls=[]\n",
    "match_page=driver.find_elements_by_xpath(\"//div[@class='js-list']/a\")  \n",
    "for i in match_page:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "  \n",
    "    \n",
    "time.sleep(1)   \n",
    "# make empty lists\n",
    "match=[] \n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "Time=[]\n",
    "all_text = []\n",
    "venue = []\n",
    "\n",
    "\n",
    "for i in urls:                 #list of urls of match description pages\n",
    "    driver.get(i)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #scarping match title\n",
    "    try:                    \n",
    "        match_title=driver.find_element_by_xpath(\"//p[@class='mc-header-info__match-description']/span\")\n",
    "        match.append(match_title.text)\n",
    "    except:#handling no such element exception\n",
    "        match.append('No details available')\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #scarping series title    \n",
    "    try:\n",
    "        series_title=driver.find_element_by_xpath(\"//h1[@class='mc-header-info__title']/strong\")\n",
    "        series.append(series_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        series.append(\"No details Available\")\n",
    "    \n",
    "    time.sleep(2)\n",
    "    #scarping date of match \n",
    "    try:\n",
    "        date_title=driver.find_element_by_xpath(\"//div[@class='mc-header-scorebox__datetime']/strong\")\n",
    "        date.append(date_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        date.append(\"No details Available\")      \n",
    "    \n",
    "    time.sleep(2)\n",
    "    #scarping time of the match    \n",
    "    try:\n",
    "        time_title=driver.find_element_by_xpath(\"//div[@class='mc-header-scorebox__datetime']/span\")\n",
    "        Time.append(time_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        Time.append(\"No details Available\")    \n",
    "      \n",
    "    time.sleep(2)\n",
    "     #scarping match venue    \n",
    "    try:\n",
    "        place_title=driver.find_element_by_xpath(\"//h1[@class='mc-header-info__title']\")\n",
    "        venue.append(place_title.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        place.append(\"No details Available\")\n",
    "        \n",
    "    \n",
    "    \n",
    "# split place from text\n",
    "for i in venue:\n",
    "    all_text.append(i.split())\n",
    "for i in all_text:\n",
    "    place.append(i[-1::]) \n",
    "    \n",
    "time.sleep(2)       \n",
    "#preparing the dataframe\n",
    "df=pd.DataFrame({\"Match\":match,\n",
    "                \"Series\":series,\n",
    "                \"Place\":place,\n",
    "                \"Date\":date,\n",
    "                \"Time\":Time})\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecac2fc",
   "metadata": {},
   "source": [
    "### 3) Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d77b9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from our URL is: <Response [403]>\n",
      "exception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception name</th>\n",
       "      <th>Exception description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception name  \\\n",
       "0         ElementNotSelectableException   \n",
       "1                NoSuchElementException   \n",
       "2                  NoSuchFrameException   \n",
       "3               NoAlertPresentException   \n",
       "4                 NoSuchWindowException   \n",
       "5        StaleElementReferenceException   \n",
       "6              SessionNotFoundException   \n",
       "7                      TimeoutException   \n",
       "8                    WebDriverException   \n",
       "9             ConnectionClosedException   \n",
       "10     ElementClickInterceptedException   \n",
       "11      ElementNotInteractableException   \n",
       "12             ErrorInResponseException   \n",
       "13  ErrorHandler.UnknownServerException   \n",
       "14         ImeActivationFailedException   \n",
       "15             ImeNotAvailableException   \n",
       "16         InsecureCertificateException   \n",
       "17             InvalidArgumentException   \n",
       "18         InvalidCookieDomainException   \n",
       "19          InvalidCoordinatesException   \n",
       "20          InvalidElementStateExceptio   \n",
       "21            InvalidSessionIdException   \n",
       "22       InvalidSwitchToTargetException   \n",
       "23                  JavascriptException   \n",
       "24                        JsonException   \n",
       "25             NoSuchAttributeException   \n",
       "26       MoveTargetOutOfBoundsException   \n",
       "27               NoSuchContextException   \n",
       "28                NoSuchCookieException   \n",
       "29                    NotFoundException   \n",
       "30          RemoteDriverServerException   \n",
       "31                  ScreenshotException   \n",
       "32           SessionNotCreatedException   \n",
       "33           UnableToSetCookieException   \n",
       "34           UnexpectedTagNameException   \n",
       "35              UnhandledAlertException   \n",
       "36      UnexpectedAlertPresentException   \n",
       "37               UnknownMethodException   \n",
       "38          UnreachableBrowserException   \n",
       "39          UnsupportedCommandException   \n",
       "\n",
       "                                Exception description  \n",
       "0   This Selenium exception occurs when an element...  \n",
       "1   This Exception occurs if an element could not ...  \n",
       "2   This Exception occurs if the frame target to b...  \n",
       "3   This Exception occurs when you switch to no pr...  \n",
       "4   This Exception occurs if the window target to ...  \n",
       "5   This Selenium exception occurs happens when th...  \n",
       "6   The WebDriver is acting after you quit the bro...  \n",
       "7   Thrown when there is not enough time for a com...  \n",
       "8   This Exception takes place when the WebDriver ...  \n",
       "9   This type of Exception takes place when there ...  \n",
       "10  The command may not be completed as the elemen...  \n",
       "11  This Selenium exception is thrown when any ele...  \n",
       "12  This happens while interacting with the Firefo...  \n",
       "13  Exception is used as a placeholder in case if ...  \n",
       "14  This expectation will occur when IME engine ac...  \n",
       "15    It takes place when IME support is unavailable.  \n",
       "16  Navigation made the user agent to hit a certif...  \n",
       "17  It occurs when an argument does not belong to ...  \n",
       "18  This happens when you try to add a cookie unde...  \n",
       "19  This type of Exception matches an interacting ...  \n",
       "20  It occurs when command can’t be finished when ...  \n",
       "21  This Exception took place when the given sessi...  \n",
       "22  This occurs when the frame or window target to...  \n",
       "23  This issue occurs while executing JavaScript g...  \n",
       "24  It occurs when you afford to get the session w...  \n",
       "25  This kind of Exception occurs when the attribu...  \n",
       "26  It takes place if the target provided to the A...  \n",
       "27           ContextAware does mobile device testing.  \n",
       "28  This Exception occurs when no cookie matching ...  \n",
       "29  This Exception is a subclass of WebDriverExcep...  \n",
       "30  This Selenium exception is thrown when the ser...  \n",
       "31            It is not possible to capture a screen.  \n",
       "32  It happens when a new session could not be suc...  \n",
       "33  This occurs if a driver is unable to set a coo...  \n",
       "34  Happens if a support class did not get a web e...  \n",
       "35  This expectation occurs when there is an alert...  \n",
       "36  It occurs when there is the appearance of an u...  \n",
       "37  This Exception happens when the requested comm...  \n",
       "38  This Exception occurs only when the browser is...  \n",
       "39  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.guru99.com/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "error = driver.find_element_by_xpath('//*[@id=\"java_technologies\"]/li[3]/a').get_attribute('href')\n",
    "driver.get(error)\n",
    "time.sleep(3)\n",
    "exception = driver.find_element_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a').get_attribute('href')\n",
    "driver.get(exception)\n",
    "\n",
    "try:\n",
    "    fixtures=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")    \n",
    "    fixtures.click()\n",
    "    driver.get(fixtures.get_attribute('href'))\n",
    "except:\n",
    "    print(\"exception\")\n",
    "\n",
    "Data = []\n",
    "table = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//td\")\n",
    "for i in table:\n",
    "    try:\n",
    "        Data.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data.append('-')\n",
    "\n",
    "Name = []\n",
    "for i in range(2,len(Data),2):\n",
    "    Name.append(Data[i])\n",
    "\n",
    "Description = []\n",
    "for i in range(3,len(Data),2):\n",
    "    Description.append(Data[i])\n",
    "\n",
    "df=pd.DataFrame({\"Exception name\": Name, \"Exception description\": Description})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c2e8a1",
   "metadata": {},
   "source": [
    "### 4) Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP at current price (19-20)\n",
    "\n",
    "D) GSDP at current price (18-19)\n",
    "\n",
    "E) Share(18-19)\n",
    "\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40761f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ElementNotInteractableException' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37956/922126042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0meconomy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mElementNotInteractableException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=100.0.4896.75)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00327413+2389011]\n\tOrdinal0 [0x002B9F61+1941345]\n\tOrdinal0 [0x001AC520+836896]\n\tOrdinal0 [0x001DA1F3+1024499]\n\tOrdinal0 [0x001CFF93+982931]\n\tOrdinal0 [0x001F414C+1130828]\n\tOrdinal0 [0x001CF974+981364]\n\tOrdinal0 [0x001F4364+1131364]\n\tOrdinal0 [0x00204302+1196802]\n\tOrdinal0 [0x001F3F66+1130342]\n\tOrdinal0 [0x001CE546+976198]\n\tOrdinal0 [0x001CF456+980054]\n\tGetHandleVerifier [0x004D9632+1727522]\n\tGetHandleVerifier [0x0058BA4D+2457661]\n\tGetHandleVerifier [0x003BEB81+569713]\n\tGetHandleVerifier [0x003BDD76+566118]\n\tOrdinal0 [0x002C0B2B+1968939]\n\tOrdinal0 [0x002C5988+1989000]\n\tOrdinal0 [0x002C5A75+1989237]\n\tOrdinal0 [0x002CECB1+2026673]\n\tBaseThreadInitThunk [0x75446739+25]\n\tRtlGetFullPathName_UEx [0x773E8AFF+1215]\n\tRtlGetFullPathName_UEx [0x773E8ACD+1165]\n\t(No symbol) [0x00000000]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_37956/922126042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0meconomy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mexcept\u001b[0m \u001b[0mElementNotInteractableException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meconomy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"exception\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ElementNotInteractableException' is not defined"
     ]
    }
   ],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the statisticstimes.com\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "try:\n",
    "    fixtures=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")    \n",
    "    fixtures.click()\n",
    "    driver.get(fixtures.get_attribute('href'))\n",
    "except:\n",
    "    print(\"exception\")\n",
    "\n",
    "#clicking on economy button\n",
    "economy=driver.find_element_by_xpath(\"//div[@class='dropdown'][2]/div/a[3]\")\n",
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "    print(\"exception\")\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#clicking on gdp of indian states\n",
    "indian_states=driver.find_element_by_xpath(\"//ul[@style='list-style-type:none;margin-left:20px;']//li[1]/a\")\n",
    "\n",
    "try:\n",
    "    indian_states.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(indian_states.get_attribute('href')) \n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping rank\n",
    "rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:                 #handling no such element exception\n",
    "    rank.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping States\n",
    "State=[]\n",
    "try:\n",
    "    states=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for i in states:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:                 #handling no such element exception\n",
    "    State.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#scraping GSDP(19-20)\n",
    "GSDP_20=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for i in info:\n",
    "        GSDP_20.append(i.text)\n",
    "except NoSuchElementException:           #handling no such element exception\n",
    "    GSDP_20.append('No details available')\n",
    "time.sleep(2)    \n",
    "    \n",
    "#scraping GSDP(18-19)\n",
    "GSDP_19=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for i in info:\n",
    "        GSDP_19.append(i.text)\n",
    "except NoSuchElementException:        #handling no such element exception\n",
    "    GSDP_19.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping share (18-19)\n",
    "share=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in info:\n",
    "        share.append(i.text)\n",
    "except NoSuchElementException:          #handling no such element exception\n",
    "    share.append('No details available')\n",
    "time.sleep(2)\n",
    "\n",
    "#scraping GDP(billion$)\n",
    "GDP_billion=[]\n",
    "try:\n",
    "    info=driver.find_elements_by_xpath(\"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for i in info:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:            #handling no such element exception\n",
    "    GDP_billion.append('No details available')\n",
    "    print(\"exception\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "\n",
    "#creatng dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':State,\n",
    "                'GSDP(19-20)':GSDP_20,\n",
    "                'GSDP(18-19)':GSDP_19,\n",
    "                'Share(18-19)':share,\n",
    "                'GDP(Billion_$)':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ae74b",
   "metadata": {},
   "source": [
    "#### 5) Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used\n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfb74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# Opening the github\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# clicking on option button\n",
    "explore=driver.find_element_by_xpath(\"//button[@class='btn-link d-lg-none mt-1 js-details-target']\")\n",
    "explore.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#finding trending option\n",
    "explore=driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3']/li[3]/a\")\n",
    "try:\n",
    "    explore.click()\n",
    "except:\n",
    "    driver.get(explore.get_attribute('href'))\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# making empty lists    \n",
    "repo_urls=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "repo_title=[]\n",
    "repo_desc=[]\n",
    "\n",
    "#scraping repositories urls\n",
    "repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\")\n",
    "for i in repos:\n",
    "    repo_urls.append(i.get_attribute('href'))\n",
    "time.sleep(2) \n",
    "\n",
    "    \n",
    "#scraping repositories title\n",
    "repo_title=[]\n",
    "try:\n",
    "    repos=driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")\n",
    "    for i in repos:\n",
    "        repo_title.append(i.text)\n",
    "except NoSuchElementException:#handling no such element exception\n",
    "    repo_title.append('No details available')\n",
    "time.sleep(3)\n",
    "    \n",
    "\n",
    "for i in repo_urls:\n",
    "    driver.get(i)\n",
    "    l=[]\n",
    "    time.sleep(3)\n",
    "    #scraping repositories discription\n",
    "    try:\n",
    "        repo = driver.find_element_by_xpath(\"/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[1]/div/p\")\n",
    "        repo_desc.append(repo.text)\n",
    "    except NoSuchElementException:\n",
    "        repo_desc.append('-')\n",
    "    \n",
    "    #scraping contributors count\n",
    "    try:\n",
    "        count=driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException:#handling no such element exception\n",
    "        Contributors_count.append('No details available')\n",
    "    time.sleep(2)\n",
    "    \n",
    "     #scraping languages used   \n",
    "    languages=driver.find_elements_by_xpath(\"//li[@class='d-inline']//a//span[1]\")\n",
    "    if languages:    \n",
    "        for i in languages:\n",
    "            l.append(i.text)\n",
    "    else:\n",
    "        l.append('No languages used')\n",
    "    Language_used.append(l)   \n",
    "    \n",
    "time.sleep(2)   \n",
    "#creating dataframe\n",
    "df=pd.DataFrame({'Title':repo_title,\n",
    "                'Description':repo_desc,\n",
    "                'Contributors_count':Contributors_count,\n",
    "                'Language_used':Language_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b637da2",
   "metadata": {},
   "source": [
    "#### 6) Scrape the details of top 100 songs on billboard.com. Url = https://www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.billboard.com/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "hot_100 = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[3]/a')\n",
    "hot_100.click()\n",
    "time.sleep(2)\n",
    "\n",
    "Song_name=[i.text for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[@class='chart-element__information__song text--truncate color--primary']\")]\n",
    "\n",
    "Artist_name=[i.text for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[@class='chart-element__information__artist text--truncate color--secondary']\")]\n",
    "\n",
    "Last_week_rank=[i.text for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class='chart-element__meta text--center color--secondary text--last']\")]\n",
    "\n",
    "Peak_rank=[i.text for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class='chart-element__meta text--center color--secondary text--peak']\")]\n",
    "\n",
    "Weeks_on_board=[i.text for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__metas chart-element__metas--large display--flex flex--y-center']/div[@class='chart-element__meta text--center color--secondary text--week']\")]\n",
    "\n",
    "# Creating data frame\n",
    "Songs=pd.DataFrame({\"SONG NAME\":Song_name, \"ARTIST\":Artist_name, \"LAST WEEK RANK\":Last_week_rank,\n",
    "                    \"PEAK RANK\":Peak_rank, \"WEEK ON BORD\":Weeks_on_board})\n",
    "Songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199f1a6",
   "metadata": {},
   "source": [
    "#### 7) Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ee362",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "rec = driver.find_element_by_xpath('/html/body/div[1]/div[1]/div/ul[1]/li[2]/a/div').click()\n",
    "driver.switch_to_window(driver.window_handles[1]) # switching window to make the main window as primary\n",
    "search = driver.find_element_by_xpath(\"//div[@class='inpWrap']/input\")\n",
    "search.send_keys('Data Science')\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()\n",
    "\n",
    "name = []\n",
    "designation = []\n",
    "company = []\n",
    "skills = []\n",
    "location = []\n",
    "\n",
    "# fetching Names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\"):\n",
    "    name.append(i.text)\n",
    "    \n",
    "# fetching Designation\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\"):\n",
    "    designation.append(i.text)\n",
    "\n",
    "# fetching Company names\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]/a[2]\"):\n",
    "    company.append(i.text)\n",
    "    \n",
    "# fetching  Skills\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\"):\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        skills.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        skills.append('-')\n",
    "                \n",
    "# fetching Locations\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]//span\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "# Creating a dataframe\n",
    "data = list(zip(name, designation, company, skills, location))\n",
    "df = pd.DataFrame(data, columns = [\"Name\", \"Designation\", \"Company Name\", \"Skills they hire for\", \"Location\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2003e8a",
   "metadata": {},
   "source": [
    "#### 8) Scrape the details of Highest selling novels. Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eab9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volume_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "try: # Scraping Book name\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[2]\"):\n",
    "        Book_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Author name\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[3]\"):\n",
    "        Author_name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "        \n",
    "try: # Scraping Volume sold\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[4]\"):\n",
    "        Volume_sold.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Publisher\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[5]\"):\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\") \n",
    "    \n",
    "try: # Scraping Genre\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='embed block']/table/tbody/tr/td[6]\"):\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "# Creating data frame \n",
    "Books=pd.DataFrame({'Book Name': Book_name, 'Author Name': Author_name, 'Volume Sold': Volume_sold,\n",
    "                    'Publisher': Publisher, 'Genre' : Genre})\n",
    "Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197227a5",
   "metadata": {},
   "source": [
    "#### 9) Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e46882",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "name = []\n",
    "year = []\n",
    "genre = []\n",
    "runtime = []\n",
    "rating = []\n",
    "vote = []\n",
    "\n",
    "try: # Scraping Name\n",
    "    for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Year span\n",
    "    for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "        year.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "        \n",
    "try: # Scraping Genre\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p/span[5]\"):\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping Run time\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p/span[3]\"):\n",
    "        runtime.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\") \n",
    "    \n",
    "try: # Scraping Ratings\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\"):\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "    \n",
    "try: # Scraping votes\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\"):\n",
    "        vote.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"-\")\n",
    "\n",
    "# Creating a dataframe \n",
    "imdb=pd.DataFrame({'Name':name, 'Year Span':year, 'Genre':genre, 'Run Time':runtime, 'Ratings':rating, 'Votes':vote})\n",
    "imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8633405",
   "metadata": {},
   "source": [
    "### 10) Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314e7c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from our URL is: <Response [200]>\n",
      "exception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Default Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of atrributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type          Default Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of instances No of atrributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/\"\n",
    "page = requests.get(url)\n",
    "print(\"Legality Response number from our URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\Thamizh\\Downloads\\chromedriver_win32 (2)\\chromedriver.exe\")\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "\n",
    "respository=driver.find_element_by_xpath(\"//span[@class='normal']/b/a\")\n",
    "respository.click() \n",
    "\n",
    "try:\n",
    "    fixtures=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div/ul/li/a\")    \n",
    "    fixtures.click()\n",
    "    driver.get(fixtures.get_attribute('href'))\n",
    "except:\n",
    "    print(\"exception\")\n",
    "    \n",
    "Name=[]\n",
    "Type=[]\n",
    "Task=[]\n",
    "Attribute=[]\n",
    "No_of_Instance=[]\n",
    "No_of_Attribute=[]\n",
    "Year=[]\n",
    "\n",
    "# Scrapping data for dataset name\n",
    "try:\n",
    "    names=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "    for i in names:\n",
    "        Name.append(i.text)\n",
    "except:\n",
    "    print(\"exception\")\n",
    "    \n",
    "# Scrapping data for data type\n",
    "try:\n",
    "    types=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]\")\n",
    "    for i in types[1:]:\n",
    "        Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Type.append('-')\n",
    "    \n",
    "# Scrapping data for default task\n",
    "try:\n",
    "    task=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]\")\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('-')\n",
    "        \n",
    "# Scrapping data for attribute type\n",
    "try:\n",
    "    attribute=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]\")\n",
    "    for i in attribute[1:]:\n",
    "        Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute.append('-')\n",
    "       \n",
    "# Scrapping data for number of instances\n",
    "try:\n",
    "    instance=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]\")\n",
    "    for i in instance[1:]:\n",
    "        No_of_Instance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instance.append('-')\n",
    "        \n",
    "# Scrapping data for number of attributes\n",
    "try:\n",
    "    attribute_no=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]\")\n",
    "    for i in attribute_no[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('-')\n",
    "        \n",
    "# Scrapping data for the year details\n",
    "try:\n",
    "    year=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]\")\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('-')\n",
    "    \n",
    "# Creating the dataframe\n",
    "df=pd.DataFrame({\"Dataset Name\":Name, \"Data Type\":Type, \"Default Task\":Task, \"Attribute Type\":Attribute, \n",
    "                 \"No of instances\":No_of_Instance, \"No of atrributes\":No_of_Attribute, \"Year\":Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca82046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9d52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02cd7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
